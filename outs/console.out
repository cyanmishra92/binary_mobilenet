Using TensorFlow backend.
60000 train samples
10000 test samples
2019-04-15 12:25:05.689861: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-04-15 12:25:05.692251: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1 (BinaryConv2D)         (None, 128, 28, 28)       1152      
_________________________________________________________________
bn1 (BatchNormalization)     (None, 128, 28, 28)       512       
_________________________________________________________________
act1 (Activation)            (None, 128, 28, 28)       0         
_________________________________________________________________
conv2 (BinaryConv2D)         (None, 128, 28, 28)       147456    
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 128, 14, 14)       0         
_________________________________________________________________
bn2 (BatchNormalization)     (None, 128, 14, 14)       512       
_________________________________________________________________
act2 (Activation)            (None, 128, 14, 14)       0         
_________________________________________________________________
conv3 (BinaryConv2D)         (None, 256, 14, 14)       294912    
_________________________________________________________________
bn3 (BatchNormalization)     (None, 256, 14, 14)       1024      
_________________________________________________________________
act3 (Activation)            (None, 256, 14, 14)       0         
_________________________________________________________________
conv4 (BinaryConv2D)         (None, 256, 14, 14)       589824    
_________________________________________________________________
pool4 (MaxPooling2D)         (None, 256, 7, 7)         0         
_________________________________________________________________
bn4 (BatchNormalization)     (None, 256, 7, 7)         1024      
_________________________________________________________________
act4 (Activation)            (None, 256, 7, 7)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12544)             0         
_________________________________________________________________
dense5 (BinaryDense)         (None, 1024)              12845056  
_________________________________________________________________
bn5 (BatchNormalization)     (None, 1024)              4096      
_________________________________________________________________
act5 (Activation)            (None, 1024)              0         
_________________________________________________________________
dense6 (BinaryDense)         (None, 10)                10240     
_________________________________________________________________
bn6 (BatchNormalization)     (None, 10)                40        
=================================================================
Total params: 13,895,848
Trainable params: 13,892,244
Non-trainable params: 3,604
_________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
60000/60000 [==============================] - 3425s 57ms/step - loss: 0.3646 - acc: 0.8709 - val_loss: 0.0878 - val_acc: 0.9427
Epoch 2/20
60000/60000 [==============================] - 3422s 57ms/step - loss: 0.0710 - acc: 0.9433 - val_loss: 0.0573 - val_acc: 0.9634
Epoch 3/20
60000/60000 [==============================] - 3422s 57ms/step - loss: 0.0470 - acc: 0.9590 - val_loss: 0.0339 - val_acc: 0.9727
Epoch 4/20
60000/60000 [==============================] - 3422s 57ms/step - loss: 0.0356 - acc: 0.9680 - val_loss: 0.0225 - val_acc: 0.9782
Epoch 5/20
60000/60000 [==============================] - 3422s 57ms/step - loss: 0.0294 - acc: 0.9728 - val_loss: 0.0214 - val_acc: 0.9796
Epoch 6/20
60000/60000 [==============================] - 3422s 57ms/step - loss: 0.0259 - acc: 0.9765 - val_loss: 0.0166 - val_acc: 0.9824
Epoch 7/20
60000/60000 [==============================] - 3423s 57ms/step - loss: 0.0239 - acc: 0.9782 - val_loss: 0.0153 - val_acc: 0.9863
Epoch 8/20
60000/60000 [==============================] - 3420s 57ms/step - loss: 0.0217 - acc: 0.9802 - val_loss: 0.0143 - val_acc: 0.9865
Epoch 9/20
60000/60000 [==============================] - 3423s 57ms/step - loss: 0.0201 - acc: 0.9816 - val_loss: 0.0145 - val_acc: 0.9873
Epoch 10/20
60000/60000 [==============================] - 3423s 57ms/step - loss: 0.0190 - acc: 0.9834 - val_loss: 0.0139 - val_acc: 0.9865
Epoch 11/20
60000/60000 [==============================] - 3422s 57ms/step - loss: 0.0180 - acc: 0.9842 - val_loss: 0.0140 - val_acc: 0.9866
Epoch 12/20
60000/60000 [==============================] - 3422s 57ms/step - loss: 0.0171 - acc: 0.9847 - val_loss: 0.0112 - val_acc: 0.9875
Epoch 13/20
60000/60000 [==============================] - 3421s 57ms/step - loss: 0.0174 - acc: 0.9851 - val_loss: 0.0109 - val_acc: 0.9887
Epoch 14/20
60000/60000 [==============================] - 3420s 57ms/step - loss: 0.0165 - acc: 0.9859 - val_loss: 0.0123 - val_acc: 0.9881
Epoch 15/20
60000/60000 [==============================] - 3419s 57ms/step - loss: 0.0159 - acc: 0.9858 - val_loss: 0.0108 - val_acc: 0.9884
Epoch 16/20
60000/60000 [==============================] - 3420s 57ms/step - loss: 0.0153 - acc: 0.9872 - val_loss: 0.0111 - val_acc: 0.9890
Epoch 17/20
60000/60000 [==============================] - 3421s 57ms/step - loss: 0.0150 - acc: 0.9872 - val_loss: 0.0096 - val_acc: 0.9897
Epoch 18/20
60000/60000 [==============================] - 3419s 57ms/step - loss: 0.0146 - acc: 0.9877 - val_loss: 0.0094 - val_acc: 0.9903
Epoch 19/20
60000/60000 [==============================] - 3420s 57ms/step - loss: 0.0148 - acc: 0.9875 - val_loss: 0.0094 - val_acc: 0.9883
Epoch 20/20
60000/60000 [==============================] - 3419s 57ms/step - loss: 0.0143 - acc: 0.9880 - val_loss: 0.0095 - val_acc: 0.9897
Test score: 0.009504017399233454
Test accuracy: 0.9897

[1]+  Done                    python mnist_cnn.py

